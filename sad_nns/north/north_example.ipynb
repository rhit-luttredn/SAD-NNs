{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORTH setup\n",
    "# from pytorch.neurops import *\n",
    "\n",
    "# import copy\n",
    "# import numpy as np\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the following cells are runable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our setup\n",
    "import torch\n",
    "from torch.functional import F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sad_nns.uncertainty import *\n",
    "from neurops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 15634 effective parameters.\n",
      "The conversion factor of this model is 4 after layer 2.\n"
     ]
    }
   ],
   "source": [
    "model = ModSequential(\n",
    "        ModConv2d(in_channels=1, out_channels=8, kernel_size=7, masked=True, padding=1, learnable_mask=True),\n",
    "        ModConv2d(in_channels=8, out_channels=16, kernel_size=7, masked=True, padding=1, prebatchnorm=True, learnable_mask=True),\n",
    "        ModConv2d(in_channels=16, out_channels=16, kernel_size=5, masked=True, prebatchnorm=True, learnable_mask=True),\n",
    "        ModLinear(64, 32, masked=True, prebatchnorm=True, learnable_mask=True),\n",
    "        ModLinear(32, 10, masked=True, prebatchnorm=True, nonlinearity=\"\"),\n",
    "        track_activations=True,\n",
    "        track_auxiliary_gradients=True,\n",
    "        input_shape = (1, 14, 14)\n",
    "    ).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"This model has {} effective parameters.\".format(model.parameter_count(masked = True)))\n",
    "print(\"The conversion factor of this model is {} after layer {}.\".format(model.conversion_factor, model.conversion_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                     transform=transforms.Compose([ \n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                            transforms.Resize((14,14))\n",
    "                        ]))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, lengths=[int(0.9*len(dataset)), int(0.1*len(dataset))])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                            transforms.Resize((14,14))\n",
    "                        ])),\n",
    "    batch_size=128, shuffle=True)\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, epochs=10, val_loader=None, verbose=True):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0 and verbose:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "        if val_loader is not None:\n",
    "            print(\"Validation: \", end = \"\")\n",
    "            test(model, val_loader, criterion)\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 2.474895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangy51/senior_research/.venv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.823869\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.461193\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.307670\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.307128\n",
      "Validation: Average loss: 0.0021, Accuracy: 5691/6000 (94.85%)\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, criterion, epochs=5, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 scores: mean 3.93, std 0.338, min 3.29, smallest 25%: [1 6]\n",
      "Layer 1 scores: mean 7.86, std 0.222, min 7.54, smallest 25%: [15 10  8  4]\n",
      "Layer 2 scores: mean 7.91, std 0.343, min 7.56, smallest 25%: [ 3  9  4 10]\n",
      "Layer 3 scores: mean 3.1, std 0.211, min 2.72, smallest 25%: [ 1 22 17 26 16  5 15 11]\n",
      "The pruned model has 9058 effective parameters.\n",
      "Validation after pruning: Average loss: 0.0081, Accuracy: 4045/6000 (67.42%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.839471\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.302044\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.279607\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.188875\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.174450\n",
      "Validation: Average loss: 0.0013, Accuracy: 5817/6000 (96.95%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.195841\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.097156\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.063645\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.055056\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.035277\n",
      "Validation: Average loss: 0.0007, Accuracy: 5823/6000 (97.05%)\n"
     ]
    }
   ],
   "source": [
    "modded_model = copy.deepcopy(model)\n",
    "modded_optimizer = torch.optim.SGD(modded_model.parameters(), lr=0.01)\n",
    "modded_optimizer.load_state_dict(optimizer.state_dict())\n",
    "\n",
    "for i in range(len(model)-1):\n",
    "    scores = weight_sum(modded_model[i].weight)\n",
    "    # scores = weight_sum(modded_model[i].weight) +  weight_sum(modded_model[i+1].weight, fanin=False, conversion_factor=model.conversion_factor if i == model.conversion_layer else -1)\n",
    "    # scores = activation_variance(modded_model.activations[str(i)])\n",
    "    # scores = svd_score(modded_model.activations[str(i)])\n",
    "    # scores = nuclear_score(modded_model.activations[str(i)], average=i<3)\n",
    "    # scores = modded_model[i+1].batchnorm.weight.abs() if i != modded_model.conversion_layer else modded_model[i+1].batchnorm.weight.abs().reshape(modded_model.conversion_factor,-1).sum(0) \n",
    "    # Before trying this line, run the following block: # scores = fisher_info(mask_grads[i])\n",
    "    print(\"Layer {} scores: mean {:.3g}, std {:.3g}, min {:.3g}, smallest 25%:\".format(i, scores.mean(), scores.std(), scores.min()), end=\" \")\n",
    "    to_prune = np.argsort(scores.detach().cpu().numpy())[:int(0.25*len(scores))]\n",
    "    print(to_prune)\n",
    "    modded_model.prune(i, to_prune, optimizer=modded_optimizer)\n",
    "print(\"The pruned model has {} effective parameters.\".format(modded_model.parameter_count(masked = True)))\n",
    "print(\"Validation after pruning: \", end = \"\")\n",
    "test(modded_model, val_loader, criterion)\n",
    "train(modded_model, train_loader, modded_optimizer, criterion, epochs=2, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_mask_grads(model):\n",
    "    mask_grads = []\n",
    "    for i in range(len(model.activations)-1):\n",
    "        mask_grads.append(torch.empty(0, *model[i].mask_vector.shape))\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        for i in range(len(model)-1):\n",
    "            mask_grads[i] = torch.cat([mask_grads[i], model[i].mask_vector.grad.detach().cpu().unsqueeze(0)])\n",
    "    return mask_grads\n",
    "\n",
    "#mask_grads = collect_mask_grads(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 scores: mean 3.87, std 0.285, min 3.57, smallest 15%: [1]\n",
      "Layer 1 scores: mean 9.2, std 0.308, min 8.52, smallest 15%: [5 6]\n",
      "Layer 2 scores: mean 9.33, std 0.425, min 8.68, smallest 15%: [6 5]\n",
      "Layer 3 scores: mean 3.65, std 0.229, min 3.04, smallest 15%: [ 3 25 16 13]\n",
      "The pruned model now has 12176 effective parameters.\n",
      "Validation after pruning: Average loss: 0.0014, Accuracy: 5688/6000 (94.80%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.460138\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.169454\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.206967\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.197009\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.116645\n",
      "Validation: Average loss: 0.0010, Accuracy: 5856/6000 (97.60%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.125865\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.113279\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.081949\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.060650\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.050473\n",
      "Validation: Average loss: 0.0006, Accuracy: 5869/6000 (97.82%)\n",
      "Layer 0 scores: mean 4.06, std 0.258, min 3.81, smallest 15%: [2]\n",
      "Layer 1 scores: mean 8.12, std 0.35, min 7.51, smallest 15%: [7 6]\n",
      "Layer 2 scores: mean 8.36, std 0.43, min 7.54, smallest 15%: [10 13]\n",
      "Layer 3 scores: mean 3.22, std 0.166, min 2.82, smallest 15%: [ 6 17 24 13]\n",
      "The pruned model now has 9058 effective parameters.\n",
      "Validation after pruning: Average loss: 0.0025, Accuracy: 5463/6000 (91.05%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.365739\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.153569\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.109128\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.128209\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.191439\n",
      "Validation: Average loss: 0.0009, Accuracy: 5864/6000 (97.73%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.109542\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.065665\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.138982\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.044863\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.113977\n",
      "Validation: Average loss: 0.0005, Accuracy: 5876/6000 (97.93%)\n",
      "Layer 0 scores: mean 4.23, std 0.262, min 3.97, smallest 15%: []\n",
      "Layer 1 scores: mean 8.52, std 0.433, min 7.97, smallest 15%: [6]\n",
      "Layer 2 scores: mean 8.14, std 0.389, min 7.67, smallest 15%: [8]\n",
      "Layer 3 scores: mean 3.09, std 0.139, min 2.89, smallest 15%: [ 4 17  9]\n",
      "The pruned model now has 7910 effective parameters.\n",
      "Validation after pruning: Average loss: 0.0014, Accuracy: 5649/6000 (94.15%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.315670\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.153345\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.115932\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.099993\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.155075\n",
      "Validation: Average loss: 0.0008, Accuracy: 5874/6000 (97.90%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.076282\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.040852\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.056147\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.030141\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.050501\n",
      "Validation: Average loss: 0.0005, Accuracy: 5877/6000 (97.95%)\n",
      "Layer 0 scores: mean 4.36, std 0.253, min 4.08, smallest 15%: []\n",
      "Layer 1 scores: mean 8.93, std 0.508, min 8.33, smallest 15%: [9]\n",
      "Layer 2 scores: mean 7.74, std 0.396, min 7.2, smallest 15%: [1]\n",
      "Layer 3 scores: mean 2.88, std 0.143, min 2.67, smallest 15%: [9 0 3]\n",
      "The pruned model now has 6836 effective parameters.\n",
      "Validation after pruning: Average loss: 0.0020, Accuracy: 5480/6000 (91.33%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.233929\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.122995\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.164876\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.136997\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.135774\n",
      "Validation: Average loss: 0.0008, Accuracy: 5865/6000 (97.75%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.105768\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.079765\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.052807\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.029398\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.058326\n",
      "Validation: Average loss: 0.0006, Accuracy: 5867/6000 (97.78%)\n",
      "Layer 0 scores: mean 4.5, std 0.258, min 4.21, smallest 15%: []\n",
      "Layer 1 scores: mean 9.35, std 0.586, min 8.66, smallest 15%: [2]\n",
      "Layer 2 scores: mean 7.44, std 0.437, min 6.9, smallest 15%: [6]\n",
      "Layer 3 scores: mean 2.69, std 0.154, min 2.43, smallest 15%: [2 3]\n",
      "The pruned model now has 5885 effective parameters.\n",
      "Validation after pruning: Average loss: 0.0011, Accuracy: 5770/6000 (96.17%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.246762\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.107844\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.124162\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.142779\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.076642\n",
      "Validation: Average loss: 0.0008, Accuracy: 5873/6000 (97.88%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.094541\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.078736\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.080405\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.170275\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.109726\n",
      "Validation: Average loss: 0.0005, Accuracy: 5884/6000 (98.07%)\n"
     ]
    }
   ],
   "source": [
    "modded_model_iterative = copy.deepcopy(model)\n",
    "modded_optimizer_iterative = torch.optim.SGD(modded_model_iterative.parameters(), lr=0.01)\n",
    "modded_optimizer_iterative.load_state_dict(optimizer.state_dict())\n",
    "\n",
    "for iter in range(5):\n",
    "    for i in range(len(modded_model_iterative)-1):\n",
    "        scores = weight_sum(modded_model_iterative[i].weight)\n",
    "        # scores = weight_sum(modded_model_iterative[i].weight) +  weight_sum(modded_model_iterative[i+1].weight, fanin=False, conversion_factor=modded_model_iterative.conversion_factor if i == modded_model_iterative.conversion_layer else -1)\n",
    "        # scores = activation_variance(modded_model_iterative.activations[str(i)])\n",
    "        # scores = svd_score(modded_model_iterative.activations[str(i)])\n",
    "        # scores = nuclear_score(modded_model_iterative.activations[str(i)], average=i<3)\n",
    "        # scores = modded_model_iterative[i+1].batchnorm.weight.abs() if i != modded_model_iterative.conversion_layer else modded_model_iterative[i+1].batchnorm.weight.abs().reshape(modded_model_iterative.conversion_factor,-1).sum(0) \n",
    "        print(\"Layer {} scores: mean {:.3g}, std {:.3g}, min {:.3g}, smallest 15%:\".format(i, scores.mean(), scores.std(), scores.min()), end=\" \")\n",
    "        to_prune = np.argsort(scores.cpu().detach().numpy())[:int(0.15*len(scores))]\n",
    "        print(to_prune)\n",
    "        modded_model_iterative.prune(i, to_prune, optimizer=modded_optimizer_iterative, clear_activations=True)\n",
    "    print(\"The pruned model now has {} effective parameters.\".format(modded_model_iterative.parameter_count(masked = True)))\n",
    "    print(\"Validation after pruning: \", end = \"\")\n",
    "    test(modded_model_iterative, val_loader, criterion)\n",
    "    train(modded_model_iterative, train_loader, modded_optimizer_iterative, criterion, epochs=2, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 score: 8/8, neurons to add: 1\n",
      "Layer 1 score: 16/16, neurons to add: 1\n",
      "Layer 2 score: 16/16, neurons to add: 1\n",
      "Layer 3 score: 32/32, neurons to add: 2\n",
      "The grown model now has 16731 effective parameters.\n",
      "Validation after growing: Average loss: 0.0021, Accuracy: 5691/6000 (94.85%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.320739\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.344209\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.220079\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.171031\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.232874\n",
      "Validation: Average loss: 0.0012, Accuracy: 5810/6000 (96.83%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.097816\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.174035\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.118701\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.123435\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.063974\n",
      "Validation: Average loss: 0.0007, Accuracy: 5850/6000 (97.50%)\n",
      "Layer 0 score: 9/9, neurons to add: 1\n",
      "Layer 1 score: 17/17, neurons to add: 1\n",
      "Layer 2 score: 17/17, neurons to add: 1\n",
      "Layer 3 score: 34/34, neurons to add: 2\n",
      "The grown model now has 19217 effective parameters.\n",
      "Validation after growing: Average loss: 0.0007, Accuracy: 5850/6000 (97.50%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.124706\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.101683\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.101405\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.151916\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.107941\n",
      "Validation: Average loss: 0.0008, Accuracy: 5872/6000 (97.87%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.090355\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.054011\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.056768\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.098868\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.071537\n",
      "Validation: Average loss: 0.0006, Accuracy: 5858/6000 (97.63%)\n",
      "Layer 0 score: 10/10, neurons to add: 1\n",
      "Layer 1 score: 18/18, neurons to add: 1\n",
      "Layer 2 score: 18/18, neurons to add: 1\n",
      "Layer 3 score: 36/36, neurons to add: 2\n",
      "The grown model now has 21867 effective parameters.\n",
      "Validation after growing: Average loss: 0.0006, Accuracy: 5858/6000 (97.63%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.153111\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.070402\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.041076\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.054468\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.066910\n",
      "Validation: Average loss: 0.0006, Accuracy: 5905/6000 (98.42%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.044701\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.103909\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.027002\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.054722\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.026562\n",
      "Validation: Average loss: 0.0005, Accuracy: 5895/6000 (98.25%)\n",
      "Layer 0 score: 11/11, neurons to add: 1\n",
      "Layer 1 score: 19/19, neurons to add: 1\n",
      "Layer 2 score: 19/19, neurons to add: 1\n",
      "Layer 3 score: 38/38, neurons to add: 2\n",
      "The grown model now has 24681 effective parameters.\n",
      "Validation after growing: Average loss: 0.0005, Accuracy: 5895/6000 (98.25%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.037436\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.080033\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.065843\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.066005\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.060179\n",
      "Validation: Average loss: 0.0005, Accuracy: 5907/6000 (98.45%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.049979\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.035977\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.020336\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.065181\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.039219\n",
      "Validation: Average loss: 0.0005, Accuracy: 5906/6000 (98.43%)\n",
      "Layer 0 score: 12/12, neurons to add: 1\n",
      "Layer 1 score: 20/20, neurons to add: 1\n",
      "Layer 2 score: 20/20, neurons to add: 1\n",
      "Layer 3 score: 40/40, neurons to add: 2\n",
      "The grown model now has 27659 effective parameters.\n",
      "Validation after growing: Average loss: 0.0005, Accuracy: 5906/6000 (98.43%)\n",
      "Train Epoch: 0 [0/54000 (0%)]\tLoss: 0.041992\n",
      "Train Epoch: 0 [12800/54000 (24%)]\tLoss: 0.033299\n",
      "Train Epoch: 0 [25600/54000 (47%)]\tLoss: 0.041529\n",
      "Train Epoch: 0 [38400/54000 (71%)]\tLoss: 0.030997\n",
      "Train Epoch: 0 [51200/54000 (95%)]\tLoss: 0.079766\n",
      "Validation: Average loss: 0.0005, Accuracy: 5908/6000 (98.47%)\n",
      "Train Epoch: 1 [0/54000 (0%)]\tLoss: 0.030120\n",
      "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.093895\n",
      "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.066126\n",
      "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.028609\n",
      "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.019351\n",
      "Validation: Average loss: 0.0004, Accuracy: 5914/6000 (98.57%)\n"
     ]
    }
   ],
   "source": [
    "modded_model_grow = copy.deepcopy(model)\n",
    "modded_optimizer_grow = torch.optim.SGD(modded_model_grow.parameters(), lr=0.01)\n",
    "modded_optimizer_grow.load_state_dict(optimizer.state_dict())\n",
    "\n",
    "for iter in range(5):\n",
    "    for i in range(len(modded_model_grow)-1):\n",
    "        #score = orthogonality_gap(modded_model_grow.activations[str(i)])\n",
    "        max_rank = modded_model_grow[i].width()\n",
    "        score = effective_rank(modded_model_grow.activations[str(i)])\n",
    "        to_add = max(score-int(0.95*max_rank), 0)\n",
    "        print(\"Layer {} score: {}/{}, neurons to add: {}\".format(i, score, max_rank, to_add))\n",
    "        modded_model_grow.grow(i, to_add, fanin_weights=\"iterative_orthogonalization\", \n",
    "                               optimizer=modded_optimizer_grow)\n",
    "    print(\"The grown model now has {} effective parameters.\".format(modded_model_grow.parameter_count(masked = True)))\n",
    "    print(\"Validation after growing: \", end = \"\")\n",
    "    test(modded_model_grow, val_loader, criterion)\n",
    "    train(modded_model_grow, train_loader, modded_optimizer_grow, criterion, epochs=2, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 scores: mean 3.87, std 0.285, min 3.57, smallest 25% to mask: [1 4], random neurons to unmask: [14 13]\n",
      "Layer 1 scores: mean 17.7, std 0.428, min 16.4, smallest 25% to mask: [ 5  1 13  6], random neurons to unmask: [28 18 17 26]\n",
      "Layer 2 scores: mean 17.8, std 0.615, min 16.8, smallest 25% to mask: [6 7 5 8], random neurons to unmask: [17 18 23 26]\n",
      "Layer 3 scores: mean 6.95, std 0.318, min 6.16, smallest 25% to mask: [ 3 25 16 20 14 19  5  9], random neurons to unmask: [63 38 58 48 50 56 47 36]\n",
      "The masked model now has 28358 effective parameters.\n",
      "Validation after growing: Average loss: 0.0130, Accuracy: 2576/6000 (42.93%)\n",
      "Validation: Average loss: 0.0011, Accuracy: 5828/6000 (97.13%)\n",
      "Validation: Average loss: 0.0007, Accuracy: 5848/6000 (97.47%)\n",
      "Layer 0 scores: mean 3.88, std 0.428, min 3.06, smallest 25% to mask: [14 13], random neurons to unmask: [ 1 12]\n",
      "Layer 1 scores: mean 17, std 1.88, min 13.4, smallest 25% to mask: [28 26 17 18], random neurons to unmask: [30 22 21  6]\n",
      "Layer 2 scores: mean 17.2, std 1.91, min 13.9, smallest 25% to mask: [23 18 17 26], random neurons to unmask: [30 21  7 22]\n",
      "Layer 3 scores: mean 6.74, std 0.659, min 5.29, smallest 25% to mask: [58 48 50 38 47 36 56 63], random neurons to unmask: [53 33 16 25 49 20 60 62]\n",
      "The masked model now has 28405 effective parameters.\n",
      "Validation after growing: Average loss: 24.6169, Accuracy: 739/6000 (12.32%)\n",
      "Validation: Average loss: 0.0008, Accuracy: 5875/6000 (97.92%)\n",
      "Validation: Average loss: 0.0005, Accuracy: 5881/6000 (98.02%)\n",
      "Layer 0 scores: mean 4.07, std 0.295, min 3.64, smallest 25% to mask: [1 3], random neurons to unmask: [14 10]\n",
      "Layer 1 scores: mean 17.4, std 1.72, min 13.7, smallest 25% to mask: [30 22 21  6], random neurons to unmask: [18 28 13 23]\n",
      "Layer 2 scores: mean 17.7, std 1.79, min 14, smallest 25% to mask: [30 22 21 12], random neurons to unmask: [19 27 18 25]\n",
      "Layer 3 scores: mean 6.87, std 0.543, min 5.49, smallest 25% to mask: [49 60 33 53 62 25 16 20], random neurons to unmask: [19 35  5 37 43 34 39 57]\n",
      "The masked model now has 28403 effective parameters.\n",
      "Validation after growing: Average loss: 53.2606, Accuracy: 454/6000 (7.57%)\n",
      "Validation: Average loss: 0.0007, Accuracy: 5875/6000 (97.92%)\n",
      "Validation: Average loss: 0.0005, Accuracy: 5880/6000 (98.00%)\n",
      "Layer 0 scores: mean 4.01, std 0.506, min 3.13, smallest 25% to mask: [14 10], random neurons to unmask: [13  9]\n",
      "Layer 1 scores: mean 17.6, std 1.85, min 13.6, smallest 25% to mask: [28 23 18 13], random neurons to unmask: [25  5 30 27]\n",
      "Layer 2 scores: mean 17.6, std 2.24, min 13.7, smallest 25% to mask: [19 25 18 27], random neurons to unmask: [24 16 29 30]\n",
      "Layer 3 scores: mean 6.88, std 0.606, min 5.27, smallest 25% to mask: [39 57 43 34 37 35  5 19], random neurons to unmask: [50 60 20 25 58 38 41 54]\n",
      "The masked model now has 28411 effective parameters.\n",
      "Validation after growing: Average loss: 17.9691, Accuracy: 654/6000 (10.90%)\n",
      "Validation: Average loss: 0.0006, Accuracy: 5886/6000 (98.10%)\n",
      "Validation: Average loss: 0.0006, Accuracy: 5877/6000 (97.95%)\n",
      "Layer 0 scores: mean 4.14, std 0.42, min 3.46, smallest 25% to mask: [ 9 13], random neurons to unmask: [14 15]\n",
      "Layer 1 scores: mean 17.7, std 2, min 13.7, smallest 25% to mask: [30 27 25  5], random neurons to unmask: [19  6 20 24]\n",
      "Layer 2 scores: mean 17.8, std 2.27, min 13.7, smallest 25% to mask: [16 30 24 29], random neurons to unmask: [27 17 18 23]\n",
      "Layer 3 scores: mean 6.85, std 0.68, min 5.28, smallest 25% to mask: [58 54 50 60 38 41 25 20], random neurons to unmask: [40 45 56 63  9 16 51 62]\n",
      "The masked model now has 28411 effective parameters.\n",
      "Validation after growing: Average loss: 22.2424, Accuracy: 845/6000 (14.08%)\n",
      "Validation: Average loss: 0.0005, Accuracy: 5895/6000 (98.25%)\n",
      "Validation: Average loss: 0.0004, Accuracy: 5908/6000 (98.47%)\n"
     ]
    }
   ],
   "source": [
    "modded_model_masked = copy.deepcopy(model)\n",
    "modded_optimizer_masked = torch.optim.SGD(modded_model_masked.parameters(), lr=0.01)\n",
    "modded_optimizer_masked.load_state_dict(optimizer.state_dict())\n",
    "\n",
    "for i in range(len(modded_model_masked)-1):\n",
    "    neurons = modded_model_masked[i].width()\n",
    "    modded_model_masked.grow(i, neurons, fanin_weights=\"kaiming\", fanout_weights=\"kaiming\", optimizer=modded_optimizer_masked)\n",
    "    modded_model_masked.mask(i, list(range(neurons, 2*neurons)))\n",
    "\n",
    "for iter in range(5):\n",
    "    for i in range(len(modded_model_masked)-1):\n",
    "        scores = weight_sum(modded_model_masked[i].get_weights())\n",
    "        print(\"Layer {} scores: mean {:.3g}, std {:.3g}, min {:.3g}, smallest 25% to mask:\".format(i, scores[scores != 0].mean(), scores[scores != 0].std(), scores[scores != 0].min()), end=\" \")\n",
    "        to_mask = np.argsort(scores.detach().numpy())[sum(scores == 0):sum(scores == 0)+int(0.25*sum(scores != 0))]\n",
    "        print(to_mask, end=\", \")\n",
    "        modded_model_masked.mask(i, to_mask)\n",
    "        to_unmask = np.argsort(scores.detach().numpy())[:sum(scores == 0)]\n",
    "        to_unmask = np.random.choice(to_unmask, size=len(to_mask), replace=False)\n",
    "        print(\"random neurons to unmask:\", to_unmask)\n",
    "        modded_model_masked.unmask(i, to_unmask, optimizer=modded_optimizer_masked)\n",
    "    print(\"The masked model now has {} effective parameters.\".format(modded_model_masked.parameter_count(masked = True)))\n",
    "    print(\"Validation after growing: \", end = \"\")\n",
    "    test(modded_model_masked, val_loader, criterion)\n",
    "    train(modded_model_masked, train_loader, modded_optimizer_masked, criterion, epochs=2, val_loader=val_loader, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modded_model_grow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodded_model_grow\u001b[49m\u001b[38;5;241m.\u001b[39mactivations\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modded_model_grow' is not defined"
     ]
    }
   ],
   "source": [
    "modded_model_grow.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
